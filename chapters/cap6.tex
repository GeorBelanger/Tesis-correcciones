Para concluir este trabajo, se dará un pequeño resumen de lo que se ha hecho, se darán algunas conclusiones generales, se describirán un poco los rumbos que ha tomado esta investigación en aprendizaje profundo y, finalmente, se darán algunos comentarios de cierre.

\vspace{1em}

En este trabajo, en primer lugar, en el capítulo 2, se revisaron los conceptos básicos y que se consideraron necesarios de aprendizaje de máquina. En segundo lugar, se revisaron los conceptos de aprendizaje profundo para dar una buena introducción y un marco teórico necesario para entender a las redes neuronales y redes neuronales recurrentes. Después en el capítulo 4 y 5 se realizaron experimentos de generación de sucesiones prediciendo un paso a la vez los siguientes datos: en el capítulo 4, el caracter que sigue basado en los anteriores y, en capítulo 5, el trazo que sigue basado en los anteriores.

\vspace{1em}

Con los experimentos, se pudo demostrar, siguiendo a (Graves, 2013), que las redes neuronales recurrentes con unidades LSTM pueden generar sucesiones discretas o reales con estructura compleja y de largo alcance al predecir un paso a la vez. También se presentó, siguiendo a Graves, el mecanismo de atención que permite sintetizar caligrafía en línea al condicionar las predicciones del modelo en un texto dado. Al mismo tiempo, también se comprobó que para hacer que los algoritmos aprendan y tengan un desempeño altamente competitivo, será necesario tener la capacidad computacional necesaria. En este trabajo, se utilizó una computadora personal y aunque los resultados no son altamente competitivos, ya se deja ver el poder que tienen los algoritmos estudiados.
\cite{DBLP:journals/corr/Graves13}

\vspace{1em}

Graves propone dos direcciones para continuar su trabajo. La primera tiene que ver con entender mejor la representación interna de los datos para manipular la distribución de sampleado directamente para hacer mejores predicciones. En esta misma línea, Graves sugiere desarrollar un mecanismo que extraiga anotaciones de alto nivel de los datos secuenciales para poder tener resultados con más estructura y poder tener información sobre los diferentes estilos, las diferentes formas de las letras y el orden de los trazos.
\cite{DBLP:journals/corr/Graves13}

\vspace{1em}

La segunda dirección que propone Graves es utilizar el modelo para hacer síntesis de voz, la cual es un poco más desafiante que la caligrafía pues hay una mayor dimensionalidad de los datos. Graves ya ha continuado esta investigación el mismo. En 2013, publicó el artículo $``$Hybrid speed recognition with deep bidirectional LSTM$"$ en el que se demuestra que su modelo también tiene buenos resultados en síntesis de voz.
\cite{DBLP:journals/corr/Graves13}

\vspace{1em}

La inteligencia artificial promete traer una revolución en muchas áreas de la vida. En los siguientes 10 o 20 años, se cree que habrá una nueva $``$revolución industrial$"$: la inteligencia artificial ayudará al humano en muchas tareas y, por otro lado, habrá muchos trabajos que dejarán de existir. Sin embargo, es importante recalcar que todos seremos más ricos pues será más barato hacer muchos productos. No obstante, será esencial crear un marco económico en el que todos se puedan beneficiar de esto y los beneficios no se vayan a unas cuantas manos. 
\cite{goodfellow-et-al-2016}

